\subsection{Метод наименьших квадратов}

\setcounter{definition}{0}
\setcounter{proposal}{0}
\setcounter{lemma}{0}
\setcounter{theorem}{0}

Часто на практике при исследовании какого-нибудь природного или социального явления делается допущение, что это явление описывается линейной формулой. Точнее, мы предполагаем, что некоторая величина $b$ линейно зависит от других величин $a_1, \ldots, a_n$, и мы хотим найти эту зависимость
\[
    b = a_1x^1 + \ldots + a_nx^n,
\]
т.\,е. найти неизвестные коэффициенты $x^1, \ldots, x^n$ (это называется \textit{моделью линейной регрессии}). Для нахождения зависимости $b$ от $a_1, \ldots, a_n$ делается большое число $m$ измерений (как правило, $m \gg n$), и по таблице измеренных значений записывается система линейных уравнений
\[
    \begin{cases}
        a_1^1x^1 + \ldots + a^1_nx^n = b^1,\\
        \dotfill\\
        a_m^1x^1 + \ldots + a^m_nx^n = b^m,
    \end{cases}
\]
в которой число неизвестных меньше числа уравнений. Такая система, как правило, несовместна. Поэтому находится <<наилучшее приближённое>> решение $x^1, \ldots, x^n$, для которого отклонение значений $b^i$ от $a_j^ix^j = a^i_1x^1 + \ldots + a^i_nx^n$ будет наименьшим.

Метод наименьших квадратов решает эту задачу нахождения наилучшего приближённого решения в предположении, что в качестве меры отклонения берётся сумма квадратов разностей величин $a^i_1x^1 + \ldots + a^i_nx^n$ и $b^i$.

\begin{definition}
    \textit{Псевдорешением} системы
    \[
        \begin{cases}
            a_1^1x^1 + \ldots + a^1_nx^n = b^1,\\
            \dotfill\\
            a_m^1x^1 + \ldots + a^m_nx^n = b^m,
        \end{cases}
    \]
    называется набор $\widetilde{x}^1, \ldots, \widetilde{x}^n$, который минимизирует сумму квадратов разностей левых и правых частей уравнений системы, т.\,е. минимизирует величину
    \[
        (a^1_jx^j - b^1)^2 + (a^2_jx^j - b^2)^2 + \ldots + (a^m_jx^j - b^m)^2
    \]
    по всем $(x^1, \ldots, x^n) \in \R^n$. Эта величина называется \textit{квадратичным отклонением}.
\end{definition}

Пусть $A = (a^i_j)$ --- матрица СЛУ, $a_1, \ldots, a_n \in \R^m$ --- вектор-столбцы этой матрицы, а $b \in \R^m$ --- вектор правых частей.

\begin{theorem}
    Псевдорешение системы $Ax = b$ находится как решение системы
    \[
        \begin{cases}
            (a_1, a_1)x^1 + \ldots + (a_1, a_n)x^n = (a_1, b),\\
            \dotfill\\
            (a_n, a_1)x^1 + \ldots + (a_n, a_n)x^n = (a_n, b).
        \end{cases}
    \]

    Другими словами, псевдорешение --- это набор коэффициентов в разложении проекции $\pr_{\langle a_1, \ldots, a_n\rangle}b$ по векторам $a_1, \ldots, a_n$, а квадратичное отклонение псевдорешения --- это квадрат длины вектора $\ort_{\langle a_1, \ldots, a_n\rangle}b$.
\end{theorem}

\begin{proof}
    Квадратичное отклонение набора $x^1, \ldots, x^n$ --- это по определению квадрат длины вектора $a_jx^j - b$, т.\,е. квадрат расстояния между векторами $b$ и $a_jx^j \in \langle a_1, \ldots, a_n\rangle$. Мы знаем из предложения 2 в вопросе 35, что расстояние между $b$ и точкой $a_jx^j$ подпространства $\langle a_1, \ldots, a_n\rangle$ минимально, когда $a_jx^j$ --- это проекция вектора $b$ на $\langle a_1, \ldots, a_n\rangle$. Коэффициенты в разложении проекции по векторам подпространства находятся из указанной системы (предложение 2 в вопросе 34), а минимальное расстояние равно $\abs{\ort_{\langle a_1, \ldots, a_n\rangle}b}$.
\end{proof}

